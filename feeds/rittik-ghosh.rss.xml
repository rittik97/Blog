<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>dark_coffee - Rittik Ghosh</title><link>rittik97.github.io/</link><description></description><lastBuildDate>Sat, 08 Feb 2020 18:44:00 -0500</lastBuildDate><item><title>Using a Neural Network to predict the Australian Open</title><link>rittik97.github.io/tennis_australian_open.html</link><description>&lt;p&gt;I was introduced to tennis when I was very young by my grandfather and have distinct memories of watching Sampras, Agassi, and Hingis. While I no longer avidly follow the sport, I wanted to use a neural network to predict tennis matches and see how it performs when compared with …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rittik Ghosh</dc:creator><pubDate>Sat, 08 Feb 2020 18:44:00 -0500</pubDate><guid isPermaLink="false">tag:None,2020-02-08:rittik97.github.io/tennis_australian_open.html</guid><category>Sports</category><category>Neural Network</category><category>Classification</category></item><item><title>Dimensionality reduction using an Autoencoder Neural Network with a comparison to PCA</title><link>rittik97.github.io/autoencoder.html</link><description>&lt;p&gt;Autoencoders are a type of artificial neural network that can be used to compress and decompress data. Being a neural network, it has the ability to learn automatically and can be used on any kind of input data. As opposed to say JPEG which can only be used on images …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rittik Ghosh</dc:creator><pubDate>Sun, 02 Feb 2020 16:55:00 -0500</pubDate><guid isPermaLink="false">tag:None,2020-02-02:rittik97.github.io/autoencoder.html</guid><category>Data Science</category><category>Dimensionality Reduction</category><category>Neural Network</category><category>Data Visualization</category><category>Feature Engineering</category></item><item><title>Simulating the english premier league with pymc3</title><link>rittik97.github.io/pymc3.html</link><description>&lt;p&gt;We will use pymc3 to simulate a season of the English Premier League. The models are based on the work of &lt;a href="https://discovery.ucl.ac.uk/id/eprint/16040/1/16040.pdf"&gt; Baio and Blangiardo.&lt;/a&gt; We are using data from the 2018-2019 season gathered from &lt;a href="https://en.wikipedia.org/wiki/2019%E2%80%9320_Premier_League#League_table"&gt;Wikipedia.&lt;/a&gt; In addition to this, each team was given an unique numeric identifier such as 0 …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rittik Ghosh</dc:creator><pubDate>Mon, 20 Jan 2020 23:00:00 -0500</pubDate><guid isPermaLink="false">tag:None,2020-01-20:rittik97.github.io/pymc3.html</guid><category>Sports</category><category>Monte Carlo Simulation</category><category>Bayesian Statistics</category></item><item><title>SMOTE (Synthetic Minority Oversampling Technique)</title><link>rittik97.github.io/SMOTE.html</link><description>&lt;p&gt;Several machine learning classification techniques tend to perform poorly on datasets where the target class (the minority class) represents a small fraction of the overall data. However, sometimes it is the minority class that we are interested in. Examples include medical applications in which we try to predict the occurrence …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rittik Ghosh</dc:creator><pubDate>Tue, 14 Jan 2020 22:05:00 -0500</pubDate><guid isPermaLink="false">tag:None,2020-01-14:rittik97.github.io/SMOTE.html</guid><category>Data Science</category><category>Decision Boundry</category><category>Oversampling</category><category>Feature Engineering</category></item><item><title>Applying PolynomialFeatures() to a subset of features in your pipeline using ColumnTransformer</title><link>rittik97.github.io/PolynomialFeatures.html</link><description>&lt;p&gt;&lt;a href='https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html'
   alt='Polynomial Features'&gt;Polynomial Features&lt;/a&gt;, which is a part of sklearn.preprocessing, allows us to feed interactions between input features to our model. It also allows us to generate higher order versions of our input features. This functionality helps us explore non-linear relationships such as income with age. It also helps us explore …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rittik Ghosh</dc:creator><pubDate>Sun, 12 Jan 2020 21:01:00 -0500</pubDate><guid isPermaLink="false">tag:None,2020-01-12:rittik97.github.io/PolynomialFeatures.html</guid><category>Data Science</category><category>Feature Engineering</category></item><item><title>Minkowski distance and its effects on KNN Classification</title><link>rittik97.github.io/Minkowski_distance.html</link><description>&lt;p&gt;Minkowski distance is a generalized version of the distance calculations we are accustomed to. It can be defined as:&lt;/p&gt;
&lt;p&gt;&lt;img src='images/min.png'&gt;
&lt;br&gt;
&lt;img src='images/Manhattan.png'&gt;&lt;/p&gt;
&lt;h6&gt;Euclidean &amp; Manhattan distance:&lt;/h6&gt;

&lt;p&gt;Manhattan distances are the sum of absolute differences between the Cartesian coordinates of the points in question. Manhattan distances can be thought of as the sum of the …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rittik Ghosh</dc:creator><pubDate>Sun, 05 Jan 2020 16:33:00 -0500</pubDate><guid isPermaLink="false">tag:None,2020-01-05:rittik97.github.io/Minkowski_distance.html</guid><category>Data Science</category><category>Decision Boundry</category><category>Classification</category></item><item><title>Visualizing the Collatz Conjecture using Altair &amp; Matplotlib</title><link>rittik97.github.io/collatz_conjecture.html</link><description>&lt;p&gt;Introduced by Lothar Collatz in 1937, the conjecture can be defined as:
start with any positive integer, if it is even divide it by two. If it is odd, triple it and add one. Now repeat this procedure to generate a sequence.&lt;/p&gt;
&lt;p&gt;The great unsolved question in mathematics is to …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rittik Ghosh</dc:creator><pubDate>Fri, 27 Dec 2019 11:35:00 -0500</pubDate><guid isPermaLink="false">tag:None,2019-12-27:rittik97.github.io/collatz_conjecture.html</guid><category>Art-ish</category><category>Data Visualization</category></item><item><title>OpenCV thresholding meets historic works of art</title><link>rittik97.github.io/opencv2thresholding.html</link><description>&lt;p&gt;OpenCV or Open source computer vision is a popular image processing library. Originally developed 20 years ago by Intel, it has found widespread adoption in computer vision applications and has over 18 million downloads. Here we explore the effects of OpenCV thresholding on historical artworks. &lt;/p&gt;
&lt;p&gt;Thresholding is exactly what it …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rittik Ghosh</dc:creator><pubDate>Sun, 22 Dec 2019 14:52:00 -0500</pubDate><guid isPermaLink="false">tag:None,2019-12-22:rittik97.github.io/opencv2thresholding.html</guid><category>Art-ish</category><category>Data Visualization</category><category>Image Processing</category></item><item><title>Demystifying matplotlib subplots</title><link>rittik97.github.io/demystifying_matplotlib_subplots.html</link><description>&lt;h1&gt;Demystifying matplotlib subplots&lt;/h1&gt;
&lt;p&gt;Everyone who has explored visualizations in python has encountered the infamous:
fig, ax= plt.subplots()&lt;/p&gt;
&lt;p&gt;However, it isn't always obvious what's happening behind the scenes. In this post, we explore what it means and how we can utilize subplots to create powerful visualizations.
The subplot function accepts …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rittik Ghosh</dc:creator><pubDate>Sun, 08 Dec 2019 23:19:00 -0500</pubDate><guid isPermaLink="false">tag:None,2019-12-08:rittik97.github.io/demystifying_matplotlib_subplots.html</guid><category>misc</category></item></channel></rss>